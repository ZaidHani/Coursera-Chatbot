{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecda3cbd-3724-485c-91c4-84a98b7c9c9b",
   "metadata": {},
   "source": [
    "# Coursera's Courses Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4029ebeb-1c98-4ea5-b020-0af7d6055be5",
   "metadata": {},
   "source": [
    "##### This notebook contians the process of building a chatbot with langchain library, using Google's Gemini as an LLM and Pinecone as a vector database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c02555-d5fb-4c69-b9b5-148f34e3ffa2",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "98b76aeb-548a-42ad-9bf6-2ebb5eb26cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate, MessagesPlaceholder\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone as pc\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain, create_history_aware_retriever, RetrievalQA\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.schema import *\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14596255-c3dd-4478-bca4-4acce6333f2b",
   "metadata": {},
   "source": [
    "## Calling APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9c8ccabb-188a-428e-922f-13e17e1a1d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY')\n",
    "GOOGLE_API_KEY = os.environ.get('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33905dbc-e666-459d-9427-958551da3eae",
   "metadata": {},
   "source": [
    "## Calling the vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "05b88031-3943-47ef-ba98-e65d2a4a647e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone_environment = 'gcp-starter'\n",
    "# Loading Pinecone\n",
    "pc = pc()\n",
    "index = pc.Index(\"mychatpot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8821d4-436e-45f8-914d-0a7b9ddec808",
   "metadata": {},
   "source": [
    "## Function for getting the answer for a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "56d37c6b-1c67-4dc5-8c4a-ea99eedd509c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(query):\n",
    "\n",
    "    model = 'models/embedding-001'\n",
    "    embed = GoogleGenerativeAIEmbeddings(model=model)\n",
    "\n",
    "    vstore = Pinecone(embedding=embed, index=index, text_key='text')\n",
    "    retriever = vstore.as_retriever(k=10)\n",
    "\n",
    "    llm = ChatGoogleGenerativeAI(model='gemini-pro', temperature=0.7 ,convert_system_message_to_human=True)\n",
    "\n",
    "    template = \"\"\"You play the role of an assistant who will help students to find courses suited to them.\n",
    "A student is going to ask you a question, your task is to answer the question using the context.\n",
    "If the question is not related to the context, guide the student to ask you about Coursera's courses.\\n\\n\n",
    "Context: \\n {context}?\\n\n",
    "Question: \\n {question} \\n\n",
    "Answer:\"\"\"\n",
    "\n",
    "    QA_CHIAN_PROMPT = PromptTemplate.from_template(template)\n",
    "\n",
    "    qa_chian = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=retriever,\n",
    "        chain_type_kwargs={\n",
    "            'prompt':QA_CHIAN_PROMPT\n",
    "        }\n",
    "    )\n",
    "    response = qa_chian.invoke(query)\n",
    "    return response['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1aeabe60-dfe9-4e65-a675-9970220d41f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. The Science of Gastronomy, rating: 4.6\\n2. More Chinese for Beginners, rating: 4.6'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer('give me some cooking courses and their ratings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4cf89e-cf54-4f2a-939d-c06de5c65975",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
